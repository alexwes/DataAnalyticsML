the rise of big tech and social media presents a series of difficult, perhaps intractable problems for western societies. our internet behemoths are effectively immense media companies pretending to be neutral platforms, feasting on the revenue that once sustained the old media ecosystem while disclaiming normal forms of editorial responsibility. their key products are agents of decentralized suspicion, generating information overload and feeding both populist paranoia and centrist hysteria. meanwhile, their leaders run transnational pseudo-governments, exerting traditional political powers -- cultural censorship, political banishment, the structuring of vast marketplaces -- without clear lines of political accountability. figuring out how to cope with these challenges is a generational political project, and there's a reasonably strong possibility that the khanate of facebook and the most serene republic of amazon will defeat the efforts of merely real-world republics to restrain their power. but still, there's a place to start that's relatively free of the policy dilemmas that shadow most plans to regulate the internet: we can try to seal off more of childhood and adolescence from social media's reach. two weeks ago the wall street journal reported on what facebook's internal research shows about how instagram, its photo-based social network, affects the mental state of the roughly 22 million teenagers who log on in the u.s. every day. the revelations will be unsurprising to anyone who has glanced at social trends since the social media era dawned, or for that matter anyone who knows anyone with teenage kids: the internal documents suggested that the app contributed to depression and anxiety, to suicidal ideation and to body-image issues for teen girls. these are hardly the first findings to link social media use and the unhappiness of young people, and whenever information like this enters the public conversation, there are two main reactions. on the one hand, from skeptics who fear a runaway moral panic and are inclined to give new technology the benefit of the doubt, there are attempts to pick apart the data, to argue that correlation isn't causation (maybe kids who are already prone to unhappiness are more likely to spend extra time online, etc.) or to point out problems and issues with the studies (the approach that facebook took in this case, effectively throwing shade on its own research). these responses assume that arguing for restraints on a product that people clearly like to use is inherently dangerous or illiberal -- and thus the burden is on the restrainers to establish ironclad proof of the danger that they fear. alternatively, from people primed to believe the evidence that social media is bad for you, there is a surge of familiar anger at the tech companies, which are accused of caring only about their numbers ("expanding its base of young users is vital to the company's more than $100 billion in annual revenue," the journal story notes of facebook, "and it doesn't want to jeopardize their engagement with the platform") instead of being socially responsible and recognizing that they're a bunch of nerds getting rich while ruining the world. my own feeling is that when you're dealing with kids, neither of these reactions is quite right. many of the problems created by internet companies involve the aggregation of decisions made, for want of a better phrase, by consenting adults. amazon has helped hollow out the american heartland, in part, because millions of people love convenience and low prices. misinformation, rumor and fake news spread on facebook, in part, because there's a strong human predisposition to share things that confirm our biases and, in this country, first amendment protections for doing so. and while it may be that the common good requires that some adult decisions be overridden or restrained, in a free society we understandably hesitate before making that kind of judgment. restraining the decisions of minors, however, is a different matter. a 14-year-old has no more of a constitutional right to use instagram than she has a constitutional right to purchase a fifth of hennessy, and strong limits on teenage access to various substances and products are a normal feature of liberal society -- opposed primarily by the kind of libertarian who identifies forever with his 13-year-old self. that libertarian's argument, in this case, boils down to the idea that if you have a novel, obviously addictive technology that might well be associated with depression, narcissism and self-harm, you need to wait for absolute certainty in that association before you start thinking about limits on how kids use it, because once upon a time there was a moral panic about comic books and wasn't that embarrassing. perhaps i've buried my 13-year-old self too deeply, but i am not convinced. but if we are willing to think about imposing limits on the teenage instagram experience, then we probably need something more than a general rage at silicon valley's reckless nerds. yes, it would be ideal if social media companies would self-regulate in their relationship to teenagers, and it's swell that in the wake of the bad wall street journal publicity facebook is temporarily putting a hold on its plans to start a version of instagram explicitly for kids. but real, sustained self-regulation generally happens only under threat of external action or with the establishment of a new consensus around what's acceptable to sell to kids. so for people who read the journal article and come away irate at facebook, the question should be, what exact consensus do you want? what norms do you expect instagram or any other company to follow? in the light of the data, what rules should they obey? and if your answer is that they should be forced to invent an algorithm that doesn't feed depression or anxiety, then i'm not sure i take your anger seriously. you're setting us up for a future of endless public promises to tweak the algorithm joined to constant behind-the-scenes pressure to get the biggest numbers possible, mental health effects be damned. (a future much like our present.) no, if you actually want to take precautionary steps that might really limit whatever damage social media is doing, you need those steps to be much simpler and blunter: you need to create a world where social media is understood to be for adults and the biggest networks are expected to police their membership and try to keep kids under 16 or 18 out. what would be lost in such a world? arguably social media supplies essential forms of connection and belonging for kids who are isolated and unhappy in their flesh-and-blood environments. (though if that's really the case, you would expect the previous decade to be an inflection point toward improved mental health for teenagers, which it definitely wasn't.) arguably it provides outlets for kids to experiment creatively and develop themselves as artists and innovators. (though the belief that tiktok is nurturing aesthetic genius sometimes feels like a philistine's delusion, nurtured by an adult establishment that lacks the self-confidence to actually educate its kids into the distinction between quality and rubbish.) in both cases, though, in a world where instagram couldn't rely on 15-year-olds to juice its stats, some of those alleged benefits of social media would still be available via the wider internet, which offered all manner of forms of community, all kinds of outlets for creativity, before twitter and facebook came along. a key problem with social media, from this perspective, isn't just its online-ness but its scale. as chris hayes puts it in a recent essay for the new yorker, the contemporary internet universalizes "the psychological experience of fame" and takes "all of the mechanisms for human relations and puts them to work" seeking more of it. but that happens in a much more profound way on a network like instagram, with all its teeming millions of users, than it would in a message board or chat room for some specific niche identity or interest. so the point of preventing teenagers from using the major social networks wouldn't be to achieve perfect compliance (obviously kids would still slip on) or to prevent some version of teenage facebook or teenage tiktok from taking shape at a smaller scale. it would be to allow for an experience of adolescence liberated from an automatic pressure to congregate on platforms built to be panopticons, to host performances geared to audiences in the tens of millions and to create addictive pressures that clearly drive fully mature adults a little bit insane. saving those adults may not be possible. but taming the internet enough to preserve a childhood free of its worst derangements -- well, if we can't accomplish even that, we deserve whatever grim future the algorithms have prepared.
