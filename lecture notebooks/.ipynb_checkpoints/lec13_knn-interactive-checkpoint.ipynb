{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## k-Nearest Neighbors\n",
    "\n",
    "adapted from Killian W, rewritten to use sklearn, and multiple other changes (PG, Sep 2019)\n",
    "\n",
    "Data is available as [digits.npy](https://courses.cit.cornell.edu/info3950_2023sp/digits.npy)\n",
    "and [faces.npy](https://courses.cit.cornell.edu/info3950_2023sp/faces.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotimage(M, c=2): # plot an image and draw a red/blue/green box around it (specified by \"d\")\n",
    "    B = np.zeros((ydim+2, xdim+2)) #with boundary\n",
    "    B[1:-1,1:-1] = M.reshape(ydim, xdim) #fill interior\n",
    "    c = ['#FF0000','#00FF00','#0000FF'][int(c)] # R, G, B\n",
    "    plt.hlines([0,ydim+1],0,xdim+1, color=c, lw=3)\n",
    "    plt.vlines([0,xdim+1],0,ydim+1, color=c, lw=3)\n",
    "    plt.imshow(B, cmap='gray', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    \n",
    "def onclick(event):\n",
    "    global who\n",
    "    preds = knn3.predict(X_test[who:who+4]) == y_test[who:who+4] #true or false for the four\n",
    "    nbrs = knn3.kneighbors(X_test[who:who+4])[1] #just the neighbors, not distances\n",
    "    \n",
    "    for i in range(4): #rows\n",
    "        plt.subplot(4,4, 4*i+1) #first column\n",
    "        plotimage(X_test[who], 2 if preds[i] else 0)  #blue or red\n",
    "        if i==0: plt.title('TEST')\n",
    "        \n",
    "        for j in range(3): #2nd through fourth columns\n",
    "            plt.subplot(4,4,4*i+j+2) \n",
    "            plotimage(X_train[nbrs[i,j]], y_train[nbrs[i,j]]==y_test[who])\n",
    "            if i==0: plt.title('{}-NN'.format(j+1))\n",
    "        who+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, X_test, y_test, xdim, ydim = np.load('faces.npy')\n",
    "X_train, y_train, X_test, y_test, xdim, ydim = np.load('digits.npy', allow_pickle=True) #first try digits data\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "knn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7291 training images and 2007 test images in the digits data, each 16x16=256 pixels.<br>\n",
    "Pixel values range from -1 to 1.<br>\n",
    "Each is labelled by the digit 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need this to suppress warnings about scipy mode change to keepdims\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning) # ignore future warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "who=0\n",
    "fig=plt.figure(figsize=(6,6))\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "onclick(None)\n",
    "print('Click to cycle through test images (blue=test, green=correct, red=wrong)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, xdim, ydim = np.load('faces.npy', allow_pickle=True) #now try faces\n",
    "#X_train, y_train, X_test, y_test, xdim, ydim = np.load('digits.npy')\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "knn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 280 training images and 120 test images in the face data, each 31x38=1178 pixels.<br>\n",
    "Pixels range in value from 0 to 245.<br>\n",
    "They consist of 10 images of each of 40 subjects, with 7 images in the training set and the other three in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "who=0\n",
    "fig=plt.figure(figsize=(6,6))\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "onclick(None)\n",
    "print('Click to cycle through test images (blue=test, green=correct, red=wrong)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the data: The underlying 16x16 digit data can be found here:<br>\n",
    "https://cs.nyu.edu/~roweis/data/_old_list<br>\n",
    "as linked from here:<br>\n",
    "https://cs.nyu.edu/~roweis/data/usps_16x16.mat<br>\n",
    "with the description:\n",
    "<blockquote>\n",
    "Handwritten digits from US post office, \"0\" through \"9\".<br>\n",
    "Two cell arrays, one for training, one for testing. d{1} is \"one\"... d{9} is \"nine\"...d{10} is \"zero\".<br>\n",
    "7291 train cases, 2007 test cases<br>\n",
    "Warning: test data comes from totally different distribution than training data. Use at your own risk.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The face images are originally from:<br>\n",
    "https://cam-orl.co.uk/facedatabase.html<br>\n",
    "with the description:<br>\n",
    "<blockquote>\n",
    "Our Database of Faces, (formerly 'The ORL Database of Faces'), contains a set of face images taken between April 1992 and April 1994 at the lab. The database was used in the context of a face recognition project carried out in collaboration with the Speech, Vision and Robotics Group of the Cambridge University Engineering Department.<br>\n",
    "There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). A [preview image](https://cam-orl.co.uk/facesataglance.html) of the Database of Faces is available.<br>\n",
    "... The size of each image is 92x112 pixels, with 256 grey levels per pixel.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,4))\n",
    "t=4 #subject 4\n",
    "for i,M in enumerate(X_train[(y_train==t).flatten()]):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plotimage(M)\n",
    "for i,M in enumerate(X_test[(y_test==t).flatten()]):\n",
    "    plt.subplot(2,5,i+8)\n",
    "    plotimage(M,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6)) #enlarged to see pixels\n",
    "plt.imshow(X_train[266].reshape(38,31), cmap='gray', interpolation='none')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same image at original 92x112 pixel resolution, with 256 grey levels per pixel\n",
    "from IPython.display import Image\n",
    "Image('s8.6.png', width=265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
