{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np, time\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-belarus",
   "metadata": {},
   "source": [
    "Redo the demo ([Example_linearvsRELUclassifier.ipynb)](https://nbviewer.jupyter.org/url/www.cs.cornell.edu/~ginsparg/Example_linearvsRELUclassifier.ipynb) using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # number of points per class\n",
    "k = 4 # number of classes\n",
    "d = 2\n",
    "\n",
    "rng = np.random.default_rng(1234) #for reproducibility\n",
    "\n",
    "################################ some 4 color spiral training data\n",
    "X_train = [[],[]] # 2d coords\n",
    "for j in range(k): #classes\n",
    "    r = np.linspace(1/n,1,n) # radius\n",
    "    theta = np.linspace(j*2*np.pi/k, (j+3.5)*2*np.pi/k, n) + .2*rng.standard_normal(n) # .84*(2pi radians) = 301degs\n",
    "    X_train[0] += list(r*np.cos(theta))\n",
    "    X_train[1] += list(r*np.sin(theta))\n",
    "\n",
    "X_train = np.array(X_train).T                            # nk x d array of data\n",
    "y_train = np.array([[i]*n for i in range(k)]).flatten()  # nk list of classes\n",
    "\n",
    "################################ some 4 color spiral test data\n",
    "X_test = [[],[]] # 2d coords\n",
    "#np.random.seed(1)\n",
    "for j in range(k): #classes\n",
    "    r = np.linspace(1/n,1,n) # radius\n",
    "    theta = np.linspace(j*2*np.pi/k, (j+3.5)*2*np.pi/k, n) + .2*rng.standard_normal(n) # .84*(2pi radians) = 301degs\n",
    "    X_test[0] += list(r*np.cos(theta))\n",
    "    X_test[1] += list(r*np.sin(theta))\n",
    "\n",
    "X_test = np.array(X_test).T                                  # nk x d array of data\n",
    "y_test = np.array([[i]*n for i in range(k)]).flatten()  # nk list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = np.array(['r','orange','y','b'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(*X_train.T, c=clrs[y_train], ec='k', s=30)\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(0,1,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn([3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit tab key for completions\n",
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadae503",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "X_train.dtype, y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fdc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = nn.Sequential(\n",
    "  nn.Linear(2,100),   #100 node layer, fully connected\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(100,4),   # connects to 4 node output layer\n",
    "#  nn.Softmax(1) #not in pytorch\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43212abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model4.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2] if name.endswith('bias') else param[:2,:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7254fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, model4(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasn't been trained yet\n",
    "y_pred = model4(X_train)\n",
    "loss = F.cross_entropy(y_pred, y_train) #-log(probability of data)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b2f32",
   "metadata": {},
   "source": [
    "four equal probabilities $p_i=1/4$, then $S -\\sum_{i=0}^3 p_i\\log p_i = -\\sum_{i=0}^3 {1\\over4}\\log{1\\over 4}\n",
    "= 4\\cdot {1\\over4}\\log4 = \\log 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use either of these to calculate accuracy score\n",
    "(y_pred.argmax(1) == y_train).numpy().mean(), (y_pred.argmax(1) == y_train).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one optimization step\n",
    "\n",
    "optimizer.zero_grad()  #zero the input gradients\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "y_pred = model4(X_train)\n",
    "loss = F.cross_entropy(y_pred, y_train)\n",
    "\n",
    "loss.item(), (y_pred.argmax(1) == y_train).numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98782ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500 # 500 steps\n",
    "scores = []\n",
    "for i in range(T):\n",
    "    optimizer.zero_grad()  #zero the input gradients\n",
    "    y_pred = model4(X_train)\n",
    "    loss = F.cross_entropy(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "loss.item(), (y_pred.argmax(1) == y_train).numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2746cde",
   "metadata": {},
   "outputs": [],
   "source": [
    ".9975*800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some convenience plot functions\n",
    "xx, yy = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
    "\n",
    "def do_plot(X,y,ax,title=None):\n",
    "    # plot resulting classifier\n",
    "    Z = model4(torch.tensor(np.c_[xx.ravel(),yy.ravel()]).float())\n",
    "    Z = Z.detach().numpy().argmax(1).reshape(xx.shape)\n",
    "    \n",
    "    if title: ax.set_title(title)\n",
    "    ax.contourf(xx,yy,Z, cmap='Spectral')\n",
    "    ax.scatter(*X.T, c=clrs[y], ec='k', s=30)\n",
    "    ax.set(xlim=(-1,1), ylim=(-1,1), aspect='equal')\n",
    "    ax.axis(False)\n",
    "    \n",
    "def do_plot_disp(X, y, ax, tsleep=0, title=None):\n",
    "    ax.cla()\n",
    "    do_plot(X,y,ax,title)\n",
    "    display.display(fig) \n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(tsleep) #was .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa603a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was already trained, so reinitialize to watch it train:\n",
    "model4 = nn.Sequential(\n",
    "  nn.Linear(2,128),   #128 node layer, fully connected\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(128,4),   # connects to 4 node output layer\n",
    "#  nn.Softmax(1) #no softmax, cross-entropy in pytorch expects logits\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(5,5))\n",
    "\n",
    "T = 500\n",
    "scores = []\n",
    "for i in range(T):\n",
    "    optimizer.zero_grad()  #zero the input gradients\n",
    "    logits = model4(X_train)\n",
    "    loss = F.cross_entropy(logits, y_train)\n",
    "    y_pred = model4(X_train)\n",
    "    nwrong = (y_pred.argmax(1) != y_train).sum().item()\n",
    "    \n",
    "    tr_score = torch.sum(y_pred.argmax(1) == y_train)/len(X_train)\n",
    "    te_score = torch.sum(model4(X_test).argmax(1) == y_test)/len(X_test)\n",
    "    scores.append([loss.item(), tr_score, te_score])\n",
    "    \n",
    "    if i<20 or i%10==0:\n",
    "        t = f'iteration {i+1}, loss: {loss:.2f}, #wrong: {nwrong}'\n",
    "        do_plot_disp(X_train, y_train, plt.gca(), .1 if i <20 else 0, t)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2, figsize=(10.9,5))\n",
    "t = f'iteration {i+1}, training score: {scores[-1][1]:.4f}'\n",
    "do_plot(X_train, y_train, ax[0],t)\n",
    "t = f'iteration {i+1}, test score: {scores[-1][2]:.4f}'\n",
    "do_plot(X_test, y_test, ax[1],t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "795/800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=np.array(scores)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(scores.T[0], label = 'loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.grid('on')\n",
    "#plt.yticks(np.arange(.3,1.01,.05))\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(scores.T[1], label='training score')\n",
    "plt.plot(scores.T[2], label = 'test score')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.grid('on')\n",
    "plt.yticks(np.arange(.3,1.01,.05))\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53086d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(scores.T[1], label='training score')\n",
    "plt.plot(scores.T[2], label = 'test score')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.grid('on')\n",
    "plt.yticks(np.arange(.3,1.01,.05))\n",
    "plt.legend(loc='upper left')\n",
    "plt.yticks(np.arange(.9,1.01,.01))\n",
    "plt.ylim(.9,1.005);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from lec20 demo\n",
    "x1_train = [-4.23356681, -3.45770474, -2.42322198, -1.49649784, -0.35425647,\n",
    "             0.4216056 ,  1.26212284,  2.25350216,  3.58970905,  4.10695043]\n",
    "y1_train = [-0.11934071, -0.66046626, -0.23838833,  0.72481513,  1.4932134,\n",
    "             1.01702292, -0.17345327, -0.76869136, -0.61717621, -0.32496842]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10/3))\n",
    "plt.plot(x1_train, y1_train, 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = torch.tensor(x1_train)[:,None].float()  #add dimension\n",
    "y1_train = torch.tensor(y1_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be138b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "model1 = nn.Sequential(\n",
    "  nn.Linear(1,N),   #N node layer, fully connected\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(N,1,bias=False),                         # connects to 4 node output layer\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4eb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not trained\n",
    "y_pred = model1(x1_train)\n",
    "F.mse_loss(y_pred.T[0], y1_train).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554a0f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.title(f'{N=}, loss={loss.item():.5f}')\n",
    "plt.plot(x1_train, y1_train, 'o');\n",
    "plt.plot(torch.linspace(-5,5,101),\n",
    "         model1(torch.linspace(-5,5,101)[:,None]).detach()[:,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()  #zero the input gradients\n",
    "y_pred = model1(x1_train)\n",
    "loss = F.mse_loss(y_pred.T[0], y1_train)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d23d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 500\n",
    "losses = []\n",
    "for i in range(T):\n",
    "    optimizer.zero_grad()  #zero the input gradients\n",
    "    y_pred = model1(x1_train)\n",
    "    loss = F.mse_loss(y_pred.T[0], y1_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cdaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f'{N=}, loss={loss.item():.5f}')\n",
    "plt.plot(x1_train, y1_train, 'o');\n",
    "plt.plot(torch.linspace(-5,5,101),\n",
    "         model1(torch.linspace(-5,5,101)[:,None]).detach()[:,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(losses, label = 'loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid('on')\n",
    "#plt.ylim(0,.01)\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a546e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58008a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f992e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
