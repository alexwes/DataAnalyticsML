{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info 3950 s7_supp\n",
    "\n",
    "data preparation for ps7 problem 1 (data from ps6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcount = Counter()\n",
    "for auth in sorted(glob('ps6data/train/*/')):\n",
    "    for f in sorted(glob(f'{auth}/*')):\n",
    "        txt = open(f).read()\n",
    "        allcount += Counter([txt[i:i+3] for i in range(len(txt)-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top4000,_ = zip(*allcount.most_common(4000)) #we'll only use first 1500 here, rest for part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 4000), (640,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingest the train set\n",
    "X_train = []\n",
    "y_train = []\n",
    "for auth in sorted(glob('ps6data/train/*')):\n",
    "    for f in sorted(glob(f'{auth}/*')):\n",
    "        txt = open(f).read()\n",
    "        c = Counter([txt[i:i+3] for i in range(len(txt)-2)])\n",
    "        X_train.append([c[tg]/len(txt) for tg in top4000])\n",
    "        y_train.append(auth.split('/')[-1])\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 4000), (200,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingest the test set\n",
    "X_test = []\n",
    "y_test = []\n",
    "for auth in sorted(glob('ps6data/test/*')):\n",
    "    for f in sorted(glob(f'{auth}/*')):\n",
    "        txt = open(f).read()\n",
    "        c = Counter([txt[i:i+3] for i in range(len(txt)-2)])\n",
    "        X_test.append([c[tg]/len(txt) for tg in top4000])\n",
    "        y_test.append(auth.split('/')[-1])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 2000), (200, 2000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "nf = 2000 # this reduces number of features or training\n",
    "\n",
    "X_train2k_scaled = scaler.fit_transform(X_train[:,:nf])\n",
    "X_test2k_scaled = scaler.transform(X_test[:,:nf])\n",
    "X_train2k_scaled.shape, X_test2k_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 4000), (200, 4000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf = 4000\n",
    "\n",
    "X_train4k_scaled = scaler.fit_transform(X_train[:,:nf])\n",
    "X_test4k_scaled = scaler.transform(X_test[:,:nf])\n",
    "X_train4k_scaled.shape, X_test4k_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.hstack([[i]*32 for i in range(20)])\n",
    "y_test = np.hstack([[i]*10 for i in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('auths20.npy',\n",
    "        np.array([X_train2k_scaled, X_test2k_scaled, X_train4k_scaled, X_test4k_scaled, y_train, y_test], dtype=object))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
